# extract_PDF

Инструмент для извлечения текста из PDF-документов с автоматическим разделением больших документов на части для удобной работы с LLM (Large Language Models).

## Описание

Скрипт автоматически обрабатывает все PDF-файлы в текущей директории, извлекает из них текст и сохраняет результаты в папку `extracted_texts`. Для больших документов скрипт автоматически разделяет текст на 2-3 части, что позволяет загружать их в LLM по частям.

## Основные возможности

- ✅ Автоматическое извлечение текста из всех PDF-файлов в директории
- ✅ Сохранение с нумерацией страниц
- ✅ Автоматическое разделение больших документов на части
- ✅ Умное разделение по абзацам (не разрывает предложения)
- ✅ Поддержка UTF-8 кодировки
- ✅ Настраиваемые параметры разделения

## Требования

- Python 3.6+
- Библиотека `pdfplumber`

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/JohnKramer-CMD/extract_PDF.git
cd extract_PDF
```

2. Установите необходимые зависимости:
```bash
pip install pdfplumber
```

## Использование

1. Поместите PDF-файлы в директорию со скриптом
2. Запустите скрипт:
```bash
python extract_and_save.py
```

3. Результаты будут сохранены в папке `extracted_texts/`

## Формат выходных файлов

### Маленькие документы (≤ 50,000 символов)
- Сохраняются как один файл: `имя_документа.txt`

### Большие документы (> 50,000 символов)
- Автоматически разделяются на 2-3 части:
  - `имя_документа_часть1_из3.txt`
  - `имя_документа_часть2_из3.txt`
  - `имя_документа_часть3_из3.txt`

Каждая часть содержит полный текст с нумерацией страниц, что позволяет загружать их в LLM по отдельности.

## Настройки

В начале файла `extract_and_save.py` можно настроить параметры разделения:

```python
MAX_CHARS_PER_PART = 50000  # Максимальное количество символов на часть
MIN_PARTS = 2                # Минимальное количество частей
MAX_PARTS = 3                # Максимальное количество частей
```

### Рекомендации по настройке для LLM:

- **GPT-3.5/GPT-4**: `MAX_CHARS_PER_PART = 50000` (примерно 12,000-15,000 токенов)
- **Claude**: `MAX_CHARS_PER_PART = 60000` (примерно 15,000-18,000 токенов)
- **Другие модели**: настройте в зависимости от лимита токенов вашей модели

## Пример работы

```
Обработка: document.pdf
  Документ большой (125000 символов), разделяем на 3 части...
  Сохранено: document_часть1_из3.txt (41667 символов)
  Сохранено: document_часть2_из3.txt (41667 символов)
  Сохранено: document_часть3_из3.txt (41666 символов)

============================================================
Извлечение завершено!
============================================================
```

## Особенности разделения

Скрипт использует умный алгоритм разделения:
- Разделение происходит по абзацам (двойной перенос строки)
- Не разрывает предложения и абзацы
- Равномерно распределяет текст между частями
- Сохраняет нумерацию страниц в каждой части

## Лицензия

MIT License

## Автор

JohnKramer-CMD
